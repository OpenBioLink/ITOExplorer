(this.webpackJsonpitoexplorer=this.webpackJsonpitoexplorer||[]).push([[0],{221:function(e,t,a){},222:function(e,t,a){},245:function(e,t,a){"use strict";a.r(t);var r=a(4),n=a.n(r),s=a(71),i=a.n(s),o=(a(221),a(78)),c=(a.p,a(222),a(72)),l=a(73),h=a(74),u=a(79),d=a(2),p=a(77);var m=a(0),g=function(e){Object(h.a)(a,e);var t=Object(u.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(l.a)(a,[{key:"componentDidMount",value:function(){var e=this;Object(p.get)(this.props.url).then((function(t){e.drawChart(t)}))}},{key:"drawChart",value:function(e){var t=this.props.width,a=t/6,r=d.b(",d"),n=d.a().startAngle((function(e){return e.x0})).endAngle((function(e){return e.x1})).padAngle((function(e){return Math.min((e.x1-e.x0)/2,.005)})).padRadius(1.5*a).innerRadius((function(e){return e.y0*a})).outerRadius((function(e){return Math.max(e.y0*a,e.y1*a-1)}));e=function(e,t){for(var a=new Map,r=new Map,n=!0,s=!0,i=!0,o=0;o<e.length;o++)(n=e[o][1])!=(s=e[o][0])&&(a.has(n)?(i=a.get(n)).push(s):i=[s],a.set(n,i));var c=function e(t){var n=a.get(t);if(n){var s=n.map((function(t){return e(t)})),i=d.h(s,(function(e){return e.value}));return d.h([i,r.get(t)]),{name:t,children:s}}return{name:t,value:r.get(t)||1}}(t);return console.log(JSON.stringify(c)),c}(e,this.props.root);var s=function(e){var t=d.c(e).sum((function(e){return e.value})).sort((function(e,t){return t.value-e.value}));return d.f().size([2*Math.PI,t.height+1])(t)}(e),i=d.e;s.each((function(e){return e.current=e}));var o=d.g("#"+this.props.id).append("svg").attr("width",t).attr("height",t).attr("viewBox",[0,0,t,t]).style("font","13px helvetica sans-serif").append("g").attr("transform","translate(".concat(t/2,",").concat(t/2,")")),c=o.append("g").selectAll("path").data(s.descendants().slice(1)).join("path").attr("fill",(function(e){return i(e.value/(.5*e.parent.value))})).attr("fill-opacity",(function(e){return p(e.current)?e.children?.6:.4:0})).attr("d",(function(e){return n(e.current)}));c.filter((function(e){return e.children})).style("cursor","pointer").on("click",u),c.append("title").text((function(e){return"".concat(e.ancestors().map((function(e){return e.data.name})).reverse().join("/"),"\n").concat(r(e.value))}));var l=o.append("g").attr("pointer-events","none").attr("text-anchor","middle").style("user-select","none").selectAll("text").data(s.descendants().slice(1)).join("text").attr("dy","0.35em").attr("fill-opacity",(function(e){return+m(e.current)})).attr("transform",(function(e){return g(e.current)})).text((function(e){return e.data.name})),h=o.append("circle").datum(s).attr("r",a).attr("fill","none").attr("pointer-events","all").on("click",u);function u(e,t){h.datum(t.parent||s),s.each((function(e){return e.target={x0:2*Math.max(0,Math.min(1,(e.x0-t.x0)/(t.x1-t.x0)))*Math.PI,x1:2*Math.max(0,Math.min(1,(e.x1-t.x0)/(t.x1-t.x0)))*Math.PI,y0:Math.max(0,e.y0-t.depth),y1:Math.max(0,e.y1-t.depth)}}));var a=o.transition().duration(750);c.transition(a).tween("data",(function(e){var t=d.d(e.current,e.target);return function(a){return e.current=t(a)}})).filter((function(e){return+this.getAttribute("fill-opacity")||p(e.target)})).attr("fill-opacity",(function(e){return p(e.target)?e.children?.6:.4:0})).attrTween("d",(function(e){return function(){return n(e.current)}})),l.filter((function(e){return+this.getAttribute("fill-opacity")||m(e.target)})).transition(a).attr("fill-opacity",(function(e){return+m(e.target)})).attrTween("transform",(function(e){return function(){return g(e.current)}}))}function p(e){return e.y1<=3&&e.y0>=1&&e.x1>e.x0}function m(e){return e.y1<=3&&e.y0>=1&&(e.y1-e.y0)*(e.x1-e.x0)>.03}function g(e){var t=(e.x0+e.x1)/2*180/Math.PI,r=(e.y0+e.y1)/2*a;return"rotate(".concat(t-90,") translate(").concat(r,",0) rotate(").concat(t<180?0:180,")")}}},{key:"render",value:function(){return Object(m.jsx)("div",{id:this.props.id,className:"mt-2 text-center"})}}]),a}(r.Component),f=g;a(244);var b=function(){var e=Object(r.useState)(!1),t=Object(o.a)(e,2);return t[0],t[1],Object(m.jsxs)("div",{className:"App",children:[Object(m.jsx)("nav",{className:"navbar navbar-expand-lg navbar-light bg-light position-fixed w-200px",children:Object(m.jsxs)("div",{className:"collapse navbar-collapse",id:"navbarSupportedContent",children:[Object(m.jsx)("a",{className:"navbar-brand m-auto",href:"#home",children:"ITO Explorer"}),Object(m.jsxs)("ul",{className:"navbar-nav mr-auto flex-column vertical-nav",children:[Object(m.jsx)("li",{className:"nav-item",children:Object(m.jsx)("a",{className:"nav-link",href:"#home",children:"Home"})}),Object(m.jsx)("li",{className:"nav-item",children:Object(m.jsx)("a",{className:"nav-link",href:"#processes",children:"Processes"})}),Object(m.jsx)("li",{className:"nav-item",children:Object(m.jsx)("a",{className:"nav-link",href:"#data",children:"Data"})}),Object(m.jsx)("li",{className:"nav-item",children:Object(m.jsx)("a",{className:"nav-link",href:"#benchmarks",children:"Benchmarks"})})]})]})}),Object(m.jsxs)("div",{className:"content",children:[Object(m.jsx)("h1",{id:"home",className:"title display-4",children:"Intelligence Task Ontology and Knowledge Graph (ITO)"}),Object(m.jsxs)("p",{align:"center",className:"mt-3 mb-5",children:[Object(m.jsx)("a",{href:"https://github.com/OpenBioLink/ITO",className:"mx-1",children:Object(m.jsx)("img",{alt:"GitHub Repo stars",src:"https://img.shields.io/github/stars/OpenBioLink/ITO?style=social"})}),Object(m.jsx)("a",{href:"https://bioportal.bioontology.org/ontologies/ITO",className:"mx-1",children:Object(m.jsx)("img",{alt:"BioPortal ontology",src:"https://img.shields.io/badge/BioPortal-ontology-success"})}),Object(m.jsx)("a",{href:"https://arxiv.org/abs/2110.01434",className:"mx-1",children:Object(m.jsx)("img",{alt:"Arxiv paper",src:"https://img.shields.io/badge/arXiv-paper-success"})})]}),Object(m.jsx)("blockquote",{className:"blockquote",children:Object(m.jsx)("p",{children:"The Intelligence Task Ontology and Knowledge Graph (ITO) provides a comprehensive, curated model of artificial intelligence tasks, benchmarks and benchmark results, including the biomedical domain."})}),"Research in artificial intelligence (AI) is addressing a growing number of tasks through a rapidly growing number of models and methodologies. This makes it difficult to keep track of where novel AI methods are successfully \u2013 or still unsuccessfully \u2013 applied, how progress is measured, how different advances might synergize with each other, and how future research should be prioritized. To help address these issues, we created the Intelligence Task Ontology and Knowledge Graph (ITO), a comprehensive, richly structured and manually curated resource on artificial intelligence tasks, benchmark results and performance metrics. The current version of ITO contain 685,560 edges, 1,100 classes representing AI processes and 1,995 properties representing performance metrics. The goal of ITO is to enable precise and network-based analyses of the global landscape of AI tasks and capabilities. ITO is based on technologies that allow for easy integration and enrichment with external data, automated inference and continuous, collaborative expert curation of underlying ontological models. We make the ITO dataset and a collection of Jupyter notebooks utilising ITO openly available.",Object(m.jsx)("h1",{id:"processes",className:"header",children:"Processes Sunburst"}),Object(m.jsx)(f,{width:"900",url:"https://raw.githubusercontent.com/OpenBioLink/ITOExplorer/main/processes.json",id:"sunburst-processes",root:"Process"}),Object(m.jsx)("h1",{id:"data",className:"header",children:"Data Sunburst"}),Object(m.jsx)(f,{width:"900",url:"https://raw.githubusercontent.com/OpenBioLink/ITOExplorer/main/data.json",id:"sunburst-data",root:"Data"}),Object(m.jsx)("h1",{id:"benchmarks",className:"header",children:"Benchmarks"}),Object(m.jsx)("h2",{id:"vp",className:"header",children:"Computer vision"}),Object(m.jsx)("h3",{children:"Trajectory for average gain ratio (task per year)"}),Object(m.jsx)("iframe",{id:"cv_traj",className:"mt-2 mb-5",style:{border:"none"},seamless:"seamless",src:"/ITOExplorer/vision_process.html",height:"725",width:"100%"}),"Global SOTA trajectory map for AI tasks in computer vision. Vertical dashes represent anchors (i.e. first results establishing a new benchmark for a given task). Arrows represent gains in a SOTA trajectory. Arrow colors represent the ratio of the gain, i.e. darker arrows represent stronger gains. AI tasks that would contain only a single arrow are not displayed.",Object(m.jsx)("h3",{children:"Comparative yearly distribution of state-of-the-art (SOTA) averaged gain ratio values"}),Object(m.jsx)("iframe",{id:"cv_bpl",className:"mt-2 mb-5",scrolling:"no",style:{border:"none",display:"block",marginLeft:"auto",marginRight:"auto"},seamless:"seamless",src:"/ITOExplorer/vision_process_bpl.html",height:"430",width:"1010px"}),"Comparative yearly distribution of state-of-the-art (SOTA) averaged gain ratio values for computer vision. Single dots in the boxplots represent the equivalent triangles values in the chart above. Anchors are not considered for this analysis.",Object(m.jsx)("iframe",{id:"cv_tbl",className:"mt-2 mb-5",scrolling:"no",style:{border:"none",display:"block",marginLeft:"auto",marginRight:"auto"},seamless:"seamless",src:"/ITOExplorer/vision_process_tbl.html",height:"400",width:"1000px"}),Object(m.jsx)("h2",{id:"nlp",className:"header",children:"Natural language processing"}),Object(m.jsx)("h3",{children:"Trajectory for average gain ratio (task per year)"}),Object(m.jsx)("iframe",{id:"cv_traj",className:"mt-2 mb-5",style:{border:"none"},seamless:"seamless",src:"/ITOExplorer/natural_language_processing.html",height:"725",width:"100%"}),"Global SOTA trajectory map for AI tasks in natural language processing. Vertical dashes represent anchors (i.e. first results establishing a new benchmark for a given task). Arrows represent gains in a SOTA trajectory. Arrow colors represent the ratio of the gain, i.e. darker arrows represent stronger gains. AI tasks that would contain only a single arrow are not displayed.",Object(m.jsx)("h3",{children:"Comparative yearly distribution of state-of-the-art (SOTA) averaged gain ratio values"}),Object(m.jsx)("iframe",{id:"cv_bpl",className:"mt-2 mb-5",scrolling:"no",style:{border:"none",display:"block",marginLeft:"auto",marginRight:"auto"},seamless:"seamless",src:"/ITOExplorer/natural_language_processing_bpl.html",height:"430",width:"1010px"}),"Comparative yearly distribution of state-of-the-art (SOTA) averaged gain ratio values for NLP. Single dots in the boxplots represent the equivalent triangles values in the chart above. Anchors are not considered for this analysis.",Object(m.jsx)("iframe",{id:"cv_tbl",className:"mt-2 mb-5",scrolling:"no",style:{border:"none",display:"block",marginLeft:"auto",marginRight:"auto"},seamless:"seamless",src:"/ITOExplorer/natural_language_processing_tbl.html",height:"400",width:"1000px"})]})]})},j=function(e){e&&e instanceof Function&&a.e(3).then(a.bind(null,246)).then((function(t){var a=t.getCLS,r=t.getFID,n=t.getFCP,s=t.getLCP,i=t.getTTFB;a(e),r(e),n(e),s(e),i(e)}))};i.a.render(Object(m.jsx)(n.a.StrictMode,{children:Object(m.jsx)(b,{})}),document.getElementById("root")),j()},77:function(e,t,a){var r=a(224);t.get=function(e){return new Promise((function(t){r.get(e).then((function(e){t(e.data)})).catch((function(e){console.log(e)}))}))}}},[[245,1,2]]]);
//# sourceMappingURL=main.8da42e24.chunk.js.map